general:
  model_type: custom_cnn
  batch_size: 8
  seed: 42
  num_cuda_workers: 2
  pinned_memory: true
  epochs: 2
  save_model: false
  test_size: 0.0
  inference_size: 0.0
  val_size: 0.0
  sweep_count: 200
  accumulation_steps: 1
  patience: 5
  use_wandb: false
  use_sweep: false
  torch_viz: false
  use_kfold: true
  k_folds: 5
  adapter_type: none-full
  save_dataloader: false
  monitor: val_acc
  mode: max
  distributed_training: false
  num_gpus: 1
  strategy: ddp
optimizer:
  optimizer_type: adamw
  adam:
    lr: 1e-4
    betas:
    - 0.99
    - 0.999
  adamw:
    lr: 0.0001
    weight_decay: 0.01
    betas:
    - 0.9
    - 0.999
  warmup:
    enabled: false
    warmup_steps: 100
    warmup_start_lr: 1e-6
    warmup_method: linear
  scheduler_type: cosine_annealing_lr
  cosine_annealing_lr:
    T_max: 50
    eta_min: 0.0
  reduce_lr_on_plateau:
    mode: max
    factor: 0.85
    patience: 3
  gradient_clipping_enabled: false
  gradient_clip_val: 5.0
  gradient_clip_algorithm: norm
dataset:
  dataset_type: urbansound8k
  data_path: datasets/UrbanSound8K/classes
  num_classes: 10
  target_sr: 16000
  target_duration: 4
  file_extension: .wav
  fold_based_split: true
augmentations:
  augmentations_per_sample: 0
  augmentations: []
  sin_distortion_min_rate: 0.1
  sin_distortion_max_rate: 0.6
  sin_distortion_p: 0.9
  polarity_inversion_p: 0.8
  gaussian_noise_min_amplitude: 0.1
  gaussian_noise_max_amplitude: 0.15
  gaussian_noise_p: 0.8
  time_mask_min_band_part: 0.01
  time_mask_max_band_part: 0.15
  time_mask_fade_duration: 0.01
  time_mask_p: 0.8
feature_extraction:
  type: melspectrogram
  sampling_rate: 16000
  n_mfcc: 40
  n_mels: 128
  n_fft: 1024
  hop_length: 128
  power: 2
none-classifier:
  task_type: AUDIO_CLASSIFICATION
none-full:
  task_type: AUDIO_CLASSIFICATION
lora:
  r: 8
  lora_alpha: 16
  target_modules:
  - key
  - value
  - query
  - dense
  lora_dropout: 0
  bias: lora_only
ia3:
  feedforward_modules:
  - key
  - value
  - query
  - dense
  target_modules:
  - key
  - value
  - query
  - dense
adalora:
  init_r: 4
  target_r: 256
  target_modules:
  - key
  - value
  - query
  - dense
  lora_alpha: 4
oft:
  r: 128
  target_modules:
  - key
  - value
  - query
  - dense
  module_dropout: 0.2
  init_weights: true
layernorm:
  target_modules:
  - layernorm_before
  - layernorm_after
  task_type: AUDIO_CLASSIFICATION
hra:
  r: 2
  target_modules:
  - key
  - value
  - query
  - dense
ssf:
  init_scale: 1.0
  init_shift: 0.5
  target_modules:
  - linear
  - dense
  - batchnorm2d
  - conv2d
batchnorm:
  target_modules:
  - batchnorm2d
lorac:
  target_modules:
  - linear
  - conv2d
  - batchnorm2d
  r: 4
  alpha: 8
  dropout: 0
bitfit:
  trainable_components:
  - bias
wandb:
  project: ast-eesc50-sweeps-baseline
  name: ast-baseline-conservative-b48-lr1e4
  reinit: true
  notes: null
  tags:
  - ast
  - esc50
  - baseline
  - conservative
  - kfold
  - none-classifier
  - batch48
  - lr1e-4
  dir: wandb
sweep:
  project: ast-esc50-sweeps-baseline
  name: ast-esc50-batch-optimizer-adapter
  method: bayes
  metric:
    name: test_acc
    goal: maximize
  parameters:
    batch_size:
      values:
      - 8
    learning_rate:
      values:
      - 1e-4
      - 5e-4
    weight_decay:
      values:
      - 0.0
      - 0.01
      - 0.1
    betas:
      values:
      - - 0.9
        - 0.999
      - - 0.99
        - 0.999
      - - 0.85
        - 0.89
      - - 0.8
        - 0.85
    gradient_clipping_enabled:
      values:
      - true
      - false
    adapter_type:
      values:
      - none-classifier
      - none-full
      - ssf
      - layernorm
      - lora
      - ia3
      - adalora
      - oft
      - hra
