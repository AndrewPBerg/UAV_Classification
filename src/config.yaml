# General configuration 
general:
  data_path: "/app/src/datasets/UAV_Dataset_9"
  num_classes: 9 # must match dataset
  model_name: "AST"
  # model_name: "BERT"
  # model_name: "MERT"
  # model_name: "HUBERT"
  # model_name: "WHISPER"
  batch_size: 8
  seed: 41
  num_cuda_workers: 4
  pinned_memory: true
  epochs: 1000
  save_model: false
  project_name: "AST_Sweeps"
  sweep_count: 10000
  test_size: 0.2
  inference_size: 0.1
  val_size: 0.1
  shuffled : false
  accumulation_steps: 5
  learning_rate: 0.006
  patience : 10
  use_wandb: true
  
  # Augmentations Configuration (still under general config)
  augmentations_per_sample: 1
  # all currently available augmenations --> ["PitchShift", "TimeStretch", "AddGaussianNoise", "Shift", "TimeMask", "Reverse", "Normalize", "GainTransition", "PolarityInversion", "Gain"]
  augmentations: ["pitch_shift", "time_stretch", "tanh_distortion", "sin_distortion", "add_noise", "polarity_inversion"]
  # transform params must be inside list for augmentations.py to process corr
  pitch_shift_min_rate: 0
  pitch_shift_max_rate: 12.0
  
  time_stretch_min_rate: 0.8
  time_stretch_max_rate: 1.25

  tanh_distortion_min_rate: 0.2
  tanh_distortion_max_rate: 0.9

  sin_distortion_min_rate: 0.2
  sin_distortion_max_rate: 0.9

  # adaptor_type: "lora"
  # adaptor_type: "ia3"
  # adaptor_type: "adalora"
  adaptor_type: "oft" # top 0.97
  # adaptor_type: "fourier"
  # adaptor_type: "layernorm"
  # adaptor_type: "none-classifier"
  # adaptor_type: "none-full"
  # adaptor_type: "moa"
  # adaptor_type: "soft-moa"


lora:
  r: 768
  lora_alpha: 8
  target_modules: ["query", "key", "value", "dense"]
  lora_dropout: 0.2
  bias: "none"
  task_type: "AUDIO_CLASSIFICATION"

ia3:
  target_modules: ["query", "key", "value", "dense"]
  feedforward_modules: ["dense"]
  task_type: "AUDIO_CLASSIFICATION"

adalora:
  init_r: 1200              # Initial rank
  target_r: 768             # Target rank
  target_modules: ["query", "key", "value", "dense"]
  lora_alpha: 16
  task_type: "AUDIO_CLASSIFICATION"

oft:
  r: 768
  target_modules: ["query", "key", "value", "dense"]
  module_dropout: 0.0
  init_weights: true

fourier:
  target_modules: ["query", "key", "value", "dense"]
  task_type: "AUDIO_CLASSIFICATION"

layernorm:
  target_modules: ["layernorm"]  # targets all LayerNorm modules
  task_type: "AUDIO_CLASSIFICATION"

moa:
  max_length: 1024  # Example AST sequence length
  final_output: 'CLS'  # How to aggregate sequence outputs
  reduction_rate: 128   # Bottleneck reduction factor
  adapter_type: 'Pfeiffer'  # 'Pfeiffer' or 'Houlsby'
  location: 'MHSA'    # 'MHSA' or 'FFN'
  adapter_module: 'bottleneck'  # 'bottleneck' or 'conformer'
  num_adapters: 3     # Number of parallel adapters

soft-moa:
  max_length: 1024  # Example AST sequence length
  final_output: 'CLS'  # How to aggregate sequence outputs
  reduction_rate: 128   # Bottleneck reduction factor
  adapter_type: 'Pfeiffer'  # 'Pfeiffer' or 'Houlsby'
  location: 'MHSA'    # 'MHSA' or 'FFN'
  adapter_module: 'bottleneck'  # 'bottleneck' or 'conformer'
  num_adapters: 3     # Number of parallel adapters
  num_slots: 8
  normalize: True
  
# Script Configuration (solo run)
wandb:
  project: "11-13 Meeting"
  name: "oft r =768"
  reinit: false
  notes: ""
  tags: "AST, LoRA"
  dir : "C:/Users/Sidewinders/Desktop/CODE/UAV_Classification_repo/notebooks/wandb"


# Sweep Configuration
sweep:
  name: "AST : pitchShift & timeStretch auto-tune"
  method: "random"
  metric:
    name: "test_acc"
    goal: "maximize"
  parameters:
    learning_rate:
      values: [0.006]
    num_augmentations:
      values: [2]
    augmentations_per_sample:
      distribution: int_uniform
      min: 1
      max: 3
    pitch_shift_min_rate:
      values: [-12.0, -9.0, -6.0, -3.0, 0]
    pitch_shift_max_rate:
      values: [0, 3.0, 6.0, 9.0, 12.0]
    time_stretch_min_rate:
      values: [0.1, 0.5, 0.8, 0.9]
    time_stretch_max_rate:
      values: [0.9, 1, 1.1, 1.25, 1.5, 1.75, 2]
