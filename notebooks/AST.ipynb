{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DESCRIPTION\n",
    "Experiment with MIT's AST (Audio Spectrogram Transformer) for UAV Classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from AST_helper.util import AudioDataset, train_test_split_custom, save_model\n",
    "from AST_helper.engine import train, inference_loop\n",
    "from AST_helper.model import auto_extractor, custom_AST\n",
    "from AST_helper.util import save_model # noqa: F401\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "\n",
    "import wandb\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "display(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:/Users/Sidewinders/Research_notebooks/Drone_classification/Research/UAV_Dataset_9\"\n",
    "model_name = \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",
    "BATCH_SIZE = 16\n",
    "SEED = 42\n",
    "EPOCHS = 10\n",
    "NUM_CUDA_WORKERS = 0\n",
    "PINNED_MEMORY = True\n",
    "SHUFFLED = True\n",
    "ACCUMULATION_STEPS = 3 # multiplies by batch size for large batch size effect.\n",
    "OPTIM_LR = 0.0001\n",
    "TRAIN_PATIENCE = 5\n",
    "multiple_runs = False\n",
    "wandb_init = False\n",
    "SAVE_MODEL = False\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "config = {\n",
    "        \"learning_rate\": OPTIM_LR,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"num_epochs\": EPOCHS,\n",
    "        \"random_seed\" : SEED,\n",
    "        \"optimizer\": \"AdamW\",\n",
    "        \"loss_function\": \"CrossEntropyLoss\"\n",
    "    }\n",
    "wandb_params = {\n",
    "        \"project\": \"vanilla_AST\",\n",
    "        \"name\": \"classifier_grad_true_lowerLR\",\n",
    "        \"reinit\": False,\n",
    "        \"notes\" : \"8457 trainable params\",\n",
    "        \"tags\": [\"AST\"],\n",
    "        \"config\": config\n",
    "    }\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==============================================================================================================\n",
       "Layer (type (var_name))                                                Param #              Trainable\n",
       "==============================================================================================================\n",
       "ASTForAudioClassification (ASTForAudioClassification)                  --                   Partial\n",
       "├─ASTModel (audio_spectrogram_transformer)                             --                   False\n",
       "│    └─ASTEmbeddings (embeddings)                                      933,888              False\n",
       "│    │    └─ASTPatchEmbeddings (patch_embeddings)                      (197,376)            False\n",
       "│    │    └─Dropout (dropout)                                          --                   --\n",
       "│    └─ASTEncoder (encoder)                                            --                   False\n",
       "│    │    └─ModuleList (layer)                                         (85,054,464)         False\n",
       "│    └─LayerNorm (layernorm)                                           (1,536)              False\n",
       "├─ASTMLPHead (classifier)                                              --                   True\n",
       "│    └─LayerNorm (layernorm)                                           1,536                True\n",
       "│    └─Linear (dense)                                                  6,921                True\n",
       "==============================================================================================================\n",
       "Total params: 86,195,721\n",
       "Trainable params: 8,457\n",
       "Non-trainable params: 86,187,264\n",
       "=============================================================================================================="
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_extractor = auto_extractor(model_name)\n",
    "\n",
    "dataset_0 = AudioDataset(data_path, feature_extractor)\n",
    "shape = dataset_0[0][0].shape\n",
    "\n",
    "train_subset, test_subset, inference_subset = train_test_split_custom(dataset_0, test_size=0.2, inference_size=0.1) \n",
    "num_classes = len(dataset_0.get_classes()) \n",
    "\n",
    "model = custom_AST(model_name, num_classes, device)\n",
    "\n",
    "summary(model,\n",
    "        col_names=[\"num_params\",\"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader_custom = DataLoader(dataset=train_subset, \n",
    "                                     batch_size=BATCH_SIZE,\n",
    "                                     num_workers=NUM_CUDA_WORKERS,\n",
    "                                     pin_memory=PINNED_MEMORY,\n",
    "                                     shuffle=SHUFFLED)\n",
    "\n",
    "test_dataloader_custom = DataLoader(dataset=test_subset,\n",
    "                                    batch_size=BATCH_SIZE, \n",
    "                                    num_workers=NUM_CUDA_WORKERS,\n",
    "                                    pin_memory=PINNED_MEMORY,\n",
    "                                    shuffle=SHUFFLED)\n",
    "\n",
    "if inference_subset: # may not be defined\n",
    "    inference_dataloader_custom = DataLoader(dataset=inference_subset,\n",
    "                                    batch_size=BATCH_SIZE, \n",
    "                                    num_workers=NUM_CUDA_WORKERS,\n",
    "                                    pin_memory=PINNED_MEMORY,\n",
    "                                    shuffle=SHUFFLED) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=OPTIM_LR)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=3) #TODO experiment w/ diff hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if wandb_init:\n",
    "    wandb.init(\n",
    "            project=wandb_params.get(\"project\"),\n",
    "            config=wandb_params.get(\"config\"),\n",
    "            name=wandb_params.get(\"name\"),\n",
    "            reinit=wandb_params.get(\"reinit\", True),\n",
    "            tags=wandb_params.get(\"tags\", []),\n",
    "            notes=wandb_params.get(\"notes\", \"\"),\n",
    "            dir=wandb_params.get(\"dir\", None)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wandb: Agent Starting Run: o3bn04sd with config:\n",
      "\tbatch_size: 64\n",
      "\tepochs: 15\n",
      "\tlearning_rate: 0.05211007753744672\n",
      "\toptimizer: adam\n",
      "wandb: Agent Starting Run: aggy3w4j with config:\n",
      "\tbatch_size: 64\n",
      "\tepochs: 5\n",
      "\tlearning_rate: 0.008980299649315186\n",
      "\toptimizer: adam\n",
      "wandb: Agent Starting Run: m8l1vqf8 with config:\n",
      "\tbatch_size: 16\n",
      "\tepochs: 15\n",
      "\tlearning_rate: 0.03771697645406378\n",
      "\toptimizer: adamW\n",
      "wandb: Agent Starting Run: 9jc0pnm0 with config:\n",
      "\tbatch_size: 64\n",
      "\tepochs: 5\n",
      "\tlearning_rate: 0.08420366782944151\n",
      "\toptimizer: adam\n",
      "wandb: Agent Starting Run: z3ru84zf with config:\n",
      "\tbatch_size: 16\n",
      "\tepochs: 5\n",
      "\tlearning_rate: 0.009585436261313113\n",
      "\toptimizer: adam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-24 13:47:19,317 - wandb.wandb_agent - ERROR - Detected 5 failed runs in a row, shutting down.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e7f8ff3fa6425faa80be67b191813c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Sidewinders\\anaconda3\\envs\\Research\\Lib\\site-packages\\transformers\\models\\audio_spectrogram_transformer\\modeling_audio_spectrogram_transformer.py:187: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  context_layer = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m wandb\u001b[38;5;241m.\u001b[39magent(sweep_id, count\u001b[38;5;241m=\u001b[39msweep_count)\n\u001b[1;32m----> 3\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloader_custom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_dataloader_custom\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m                \u001b[49m\u001b[43maccumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mACCUMULATION_STEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAIN_PATIENCE\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sidewinders\\Research_notebooks\\Drone_classification\\Research\\notebooks\\AST_helper\\engine.py:136\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_dataloader, test_dataloader, optimizer, scheduler, loss_fn, epochs, device, accumulation_steps, patience, delta, num_classes)\u001b[0m\n\u001b[0;32m    133\u001b[0m train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m    134\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m--> 136\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    137\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sidewinders\\anaconda3\\envs\\Research\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Sidewinders\\anaconda3\\envs\\Research\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Sidewinders\\anaconda3\\envs\\Research\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Sidewinders\\anaconda3\\envs\\Research\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Sidewinders\\anaconda3\\envs\\Research\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "File \u001b[1;32mc:\\Users\\Sidewinders\\Research_notebooks\\Drone_classification\\Research\\notebooks\\AST_helper\\util.py:54\u001b[0m, in \u001b[0;36mAudioDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     51\u001b[0m class_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_to_idx[class_name]\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# Using the AST model's correct size for transformation instead of mel_spectrogram\u001b[39;00m\n\u001b[1;32m---> 54\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio_tensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m16000\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# adjust sampling rate as needed\u001b[39;00m\n\u001b[0;32m     55\u001b[0m inputs \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# Extract input tensor\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m inputs, class_idx\n",
      "File \u001b[1;32mc:\\Users\\Sidewinders\\anaconda3\\envs\\Research\\Lib\\site-packages\\transformers\\models\\audio_spectrogram_transformer\\feature_extraction_audio_spectrogram_transformer.py:219\u001b[0m, in \u001b[0;36mASTFeatureExtractor.__call__\u001b[1;34m(self, raw_speech, sampling_rate, return_tensors, **kwargs)\u001b[0m\n\u001b[0;32m    216\u001b[0m     raw_speech \u001b[38;5;241m=\u001b[39m [raw_speech]\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# extract fbank features and pad/truncate to max_length\u001b[39;00m\n\u001b[1;32m--> 219\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_fbank_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraw_speech\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;66;03m# convert into BatchFeature\u001b[39;00m\n\u001b[0;32m    222\u001b[0m padded_inputs \u001b[38;5;241m=\u001b[39m BatchFeature({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m\"\u001b[39m: features})\n",
      "File \u001b[1;32mc:\\Users\\Sidewinders\\anaconda3\\envs\\Research\\Lib\\site-packages\\transformers\\models\\audio_spectrogram_transformer\\feature_extraction_audio_spectrogram_transformer.py:219\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    216\u001b[0m     raw_speech \u001b[38;5;241m=\u001b[39m [raw_speech]\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# extract fbank features and pad/truncate to max_length\u001b[39;00m\n\u001b[1;32m--> 219\u001b[0m features \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_extract_fbank_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m waveform \u001b[38;5;129;01min\u001b[39;00m raw_speech]\n\u001b[0;32m    221\u001b[0m \u001b[38;5;66;03m# convert into BatchFeature\u001b[39;00m\n\u001b[0;32m    222\u001b[0m padded_inputs \u001b[38;5;241m=\u001b[39m BatchFeature({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_values\u001b[39m\u001b[38;5;124m\"\u001b[39m: features})\n",
      "File \u001b[1;32mc:\\Users\\Sidewinders\\anaconda3\\envs\\Research\\Lib\\site-packages\\transformers\\models\\audio_spectrogram_transformer\\feature_extraction_audio_spectrogram_transformer.py:119\u001b[0m, in \u001b[0;36mASTFeatureExtractor._extract_fbank_features\u001b[1;34m(self, waveform, max_length)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_speech_available():\n\u001b[0;32m    118\u001b[0m     waveform \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfrom_numpy(waveform)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 119\u001b[0m     fbank \u001b[38;5;241m=\u001b[39m \u001b[43mta_kaldi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfbank\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwaveform\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_frequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msampling_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    122\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwindow_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhanning\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    123\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_mel_bins\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_mel_bins\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    124\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m     waveform \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(waveform)\n",
      "File \u001b[1;32mc:\\Users\\Sidewinders\\anaconda3\\envs\\Research\\Lib\\site-packages\\torchaudio\\compliance\\kaldi.py:630\u001b[0m, in \u001b[0;36mfbank\u001b[1;34m(waveform, blackman_coeff, channel, dither, energy_floor, frame_length, frame_shift, high_freq, htk_compat, low_freq, min_duration, num_mel_bins, preemphasis_coefficient, raw_energy, remove_dc_offset, round_to_power_of_two, sample_frequency, snip_edges, subtract_mean, use_energy, use_log_fbank, use_power, vtln_high, vtln_low, vtln_warp, window_type)\u001b[0m\n\u001b[0;32m    627\u001b[0m mel_energies \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mpad(mel_energies, (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m), mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconstant\u001b[39m\u001b[38;5;124m\"\u001b[39m, value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    629\u001b[0m \u001b[38;5;66;03m# sum with mel fiterbanks over the power spectrum, size (m, num_mel_bins)\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m mel_energies \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspectrum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmel_energies\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_log_fbank:\n\u001b[0;32m    632\u001b[0m     \u001b[38;5;66;03m# avoid log of zero (which should be prevented anyway by dithering)\u001b[39;00m\n\u001b[0;32m    633\u001b[0m     mel_energies \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(mel_energies, _get_epsilon(device, dtype))\u001b[38;5;241m.\u001b[39mlog()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "results = train(model,\n",
    "                train_dataloader=train_dataloader_custom,\n",
    "                test_dataloader=test_dataloader_custom,\n",
    "                optimizer=optimizer,\n",
    "                scheduler=scheduler,\n",
    "                loss_fn=loss_fn,\n",
    "                epochs=EPOCHS,\n",
    "                device=device,\n",
    "                accumulation_steps=ACCUMULATION_STEPS,\n",
    "                patience=TRAIN_PATIENCE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_loop(model=model,\n",
    "               device=device,\n",
    "               loss_fn=loss_fn,\n",
    "               inference_loader= inference_dataloader_custom)\n",
    "\n",
    "\n",
    "\n",
    "if not multiple_runs and wandb_init:\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saving model to: saved_models\\AST_classifier_true.pt\n"
     ]
    }
   ],
   "source": [
    "if SAVE_MODEL:\n",
    "    save_model(model=model,\n",
    "            target_dir=\"saved_models\",\n",
    "            model_name=\"AST_classifier_true.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
