{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DESCRIPTION\n",
    "Experiment with MIT's AST (Audio Spectrogram Transformer) for UAV Classification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTES\n",
    "- add inference metric to sweep loop\n",
    "- change schedular "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AST_helper.util import AudioDataset, train_test_split_custom, save_model\n",
    "from AST_helper.engine import sweep_train, inference_loop\n",
    "from AST_helper.model import auto_extractor, custom_AST\n",
    "from AST_helper.util import save_model # noqa: F401\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchinfo import summary\n",
    "\n",
    "import wandb\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "display(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"C:/Users/Sidewinders/Desktop/CODE/UAV_Classification_repo/UAV_Dataset_9\"\n",
    "model_name = \"MIT/ast-finetuned-audioset-10-10-0.4593\"\n",
    "BATCH_SIZE = 16\n",
    "SEED = 42\n",
    "NUM_CUDA_WORKERS = 0\n",
    "NUM_CLASSES =  9 \n",
    "EPOCHS = 7\n",
    "PINNED_MEMORY = True\n",
    "SHUFFLED = True\n",
    "ACCUMULATION_STEPS = 3 # multiplies by batch size for large batch size effect.\n",
    "SAVE_MODEL = False\n",
    "PROJECT_NAME = \"AST_Sweeps\"\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    \"name\": \"accumulation_steps\",\n",
    "    \"method\": \"random\",\n",
    "    \"metric\": {\"goal\": \"maximize\", \"name\": \"test_acc\"},\n",
    "    \"parameters\": {\n",
    "        \"learning_rate\": {\"distribution\":\"uniform\",\"min\": 0.0009, \"max\": 0.005},\n",
    "        \"batch_size\": {\"values\": [4,8,16]},\n",
    "        \"epochs\" : {\"values\" : [7]},\n",
    "        \"optimizer\" : {\"values\" : [\"adamW\"]},\n",
    "        \"scheduler\" : {\"values\" : [\"ReduceLROnPlateau\"]},\n",
    "        \"accumulation_steps\" : {\"values\" : [1,2,3]}\n",
    "\n",
    "        }    \n",
    "}\n",
    "sweep_id = wandb.sweep(sweep_config, project=PROJECT_NAME)\n",
    "sweep_count = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make(config):\n",
    "    # Make the data\n",
    "    feature_extractor = auto_extractor(model_name)\n",
    "\n",
    "    dataset = AudioDataset(data_path, feature_extractor)\n",
    "    train_subset, test_subset = train_test_split_custom(dataset, test_size=0.2)  # type: ignore\n",
    "\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_subset, \n",
    "                                         batch_size=config.batch_size,\n",
    "                                         num_workers=NUM_CUDA_WORKERS,\n",
    "                                         pin_memory=PINNED_MEMORY,\n",
    "                                         shuffle=SHUFFLED)\n",
    "    \n",
    "    test_loader = DataLoader(dataset=test_subset,\n",
    "                                        batch_size=config.batch_size, \n",
    "                                        num_workers=NUM_CUDA_WORKERS,\n",
    "                                        pin_memory=PINNED_MEMORY,\n",
    "                                        shuffle=SHUFFLED)\n",
    "    \n",
    "    # if inference_subset: # may not be defined\n",
    "    #     inference_dataloader_custom = DataLoader(dataset=inference_subset,\n",
    "    #                                     batch_size=config.batch_size, \n",
    "    #                                     num_workers=NUM_CUDA_WORKERS,\n",
    "    #                                     pin_memory=PINNED_MEMORY,\n",
    "    #                                     shuffle=SHUFFLED) \n",
    "\n",
    "    # Make the model\n",
    "    model = custom_AST(model_name, NUM_CLASSES, device)\n",
    "\n",
    "    # Make the loss and optimizer\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(),\n",
    "                              lr=config.learning_rate)\n",
    "    \n",
    "    \n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=2) \n",
    "\n",
    "    return model, train_loader, test_loader, criterion, optimizer, scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline(config=None):\n",
    "\n",
    "    # tell wandb to get started\n",
    "    with wandb.init(config):\n",
    "      # access all HPs through wandb.config, so logging matches execution!\n",
    "      config = wandb.config\n",
    "      # make the model, data, and optimization problem\n",
    "      model, train_loader, test_loader, criterion, optimizer, scheduler = make(config)\n",
    "      print(model)\n",
    "\n",
    "      results = sweep_train(model,\n",
    "                      train_dataloader=train_loader,\n",
    "                      test_dataloader=test_loader,\n",
    "                      optimizer=optimizer,\n",
    "                      scheduler=scheduler,\n",
    "                      loss_fn=criterion,\n",
    "                      epochs=config.epochs, # type: ignore\n",
    "                      device=device,\n",
    "                      num_classes=NUM_CLASSES,\n",
    "                      accumulation_steps= config.accumulation_steps # type: ignore #TODO change typing to sweeps format \n",
    "                      # patience=TRAIN_PATIENCE)\n",
    "                      )\n",
    "      \n",
    "      inference_loop(model=model,\n",
    "               device=device,\n",
    "               loss_fn=criterion,\n",
    "               inference_loader= train_loader)\n",
    "\n",
    "    return model, results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model,result = model_pipeline(config)\n",
    "wandb.agent(sweep_id, model_pipeline, count=sweep_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if SAVE_MODEL:\n",
    "#     save_model(model=model,\n",
    "#             target_dir=\"saved_models\",\n",
    "#             model_name=\"AST_classifier_true.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Research",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
